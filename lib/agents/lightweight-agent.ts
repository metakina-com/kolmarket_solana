/**
 * è½»é‡çº§ AI Agent ç³»ç»Ÿ
 * ä½¿ç”¨ Vercel AI SDK æ›¿ä»£ ElizaOS + LangChain
 * åŒ…ä½“ç§¯: ~200KB vs ~15MB
 */

import { generateText, streamText } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';
import { getKOLPersona, getDefaultSystemPrompt } from './kol-personas';

// ============ ç±»å‹å®šä¹‰ ============

export interface AgentConfig {
  provider: 'openai' | 'cloudflare' | 'auto';
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

export interface AgentMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface AgentContext {
  kolHandle?: string;
  useRAG?: boolean;
  ragContext?: string[];
  conversationHistory?: AgentMessage[];
}

export interface AgentResponse {
  text: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
  };
  finishReason?: string;
}

// ============ Provider é…ç½® ============

const DEFAULT_CONFIG: AgentConfig = {
  provider: 'auto',
  temperature: 0.7,
  maxTokens: 500,
};

/**
 * åˆ›å»º OpenAI å…¼å®¹çš„ provider
 * æ”¯æŒ OpenAI API æˆ–å…¼å®¹ API (å¦‚ Groq, Together, etc.)
 */
function createProvider(config: AgentConfig) {
  const apiKey = process.env.OPENAI_API_KEY;
  const baseURL = process.env.OPENAI_BASE_URL;

  if (!apiKey) {
    return null;
  }

  return createOpenAI({
    apiKey,
    baseURL: baseURL || undefined,
  });
}

// ============ ç®€åŒ–å·¥å…· (ä¸ä½¿ç”¨ tool helper) ============

async function getTokenPrice(symbol: string): Promise<{ symbol: string; price: number; currency: string }> {
  const mockPrices: Record<string, number> = {
    SOL: 150,
    BTC: 95000,
    ETH: 3500,
    KMT: 0.05,
  };
  const price = mockPrices[symbol.toUpperCase()] || 0;
  return { symbol: symbol.toUpperCase(), price, currency: 'USD' };
}

// ============ æ ¸å¿ƒ Agent å‡½æ•° ============

/**
 * æ„å»ºç³»ç»Ÿæç¤ºè¯
 */
function buildSystemPrompt(context: AgentContext): string {
  let systemPrompt: string;

  if (context.kolHandle) {
    const persona = getKOLPersona(context.kolHandle);
    systemPrompt = persona?.systemPrompt || getDefaultSystemPrompt(context.kolHandle);
  } else {
    systemPrompt = getDefaultSystemPrompt();
  }

  // æ·»åŠ  RAG ä¸Šä¸‹æ–‡
  if (context.useRAG && context.ragContext && context.ragContext.length > 0) {
    const contextText = context.ragContext
      .map((c, idx) => `[${idx + 1}] ${c}`)
      .join('\n\n');
    systemPrompt += `\n\n## Reference Knowledge:\n${contextText}\n\nUse this knowledge to inform your responses when relevant.`;
  }

  return systemPrompt;
}

/**
 * ä½¿ç”¨ Vercel AI SDK ç”Ÿæˆå“åº”
 */
export async function generateAgentResponse(
  prompt: string,
  context: AgentContext = {},
  config: AgentConfig = DEFAULT_CONFIG
): Promise<AgentResponse> {
  const provider = createProvider(config);
  const systemPrompt = buildSystemPrompt(context);

  // æ„å»ºæ¶ˆæ¯
  const messages: AgentMessage[] = [];
  
  if (context.conversationHistory) {
    messages.push(...context.conversationHistory);
  }
  
  messages.push({ role: 'user', content: prompt });

  // å¦‚æœæœ‰ OpenAI providerï¼Œä½¿ç”¨å®ƒ
  if (provider) {
    try {
      const model = config.model || 'gpt-4o-mini';
      const result = await generateText({
        model: provider(model),
        system: systemPrompt,
        messages: messages.map(m => ({ role: m.role as 'user' | 'assistant', content: m.content })),
        temperature: config.temperature,
        maxOutputTokens: config.maxTokens,
      });

      return {
        text: result.text,
        usage: result.usage ? {
          promptTokens: (result.usage as any).promptTokens ?? 0,
          completionTokens: (result.usage as any).completionTokens ?? 0,
        } : undefined,
        finishReason: result.finishReason,
      };
    } catch (error) {
      console.warn('OpenAI generation failed, will try fallback:', error);
    }
  }

  // Fallback: è¿”å› demo å“åº”
  return generateFallbackResponse(prompt, context);
}

/**
 * æµå¼ç”Ÿæˆå“åº” (ç”¨äºå®æ—¶ UI)
 */
export async function streamAgentResponse(
  prompt: string,
  context: AgentContext = {},
  config: AgentConfig = DEFAULT_CONFIG
) {
  const provider = createProvider(config);
  const systemPrompt = buildSystemPrompt(context);

  if (!provider) {
    throw new Error('No AI provider configured. Set OPENAI_API_KEY.');
  }

  const model = config.model || 'gpt-4o-mini';
  
  return streamText({
    model: provider(model),
    system: systemPrompt,
    messages: [{ role: 'user' as const, content: prompt }],
    temperature: config.temperature,
    maxOutputTokens: config.maxTokens,
  });
}

/**
 * å¸¦å·¥å…·è°ƒç”¨çš„ Agent (ç®€åŒ–ç‰ˆï¼Œå·¥å…·ç»“æœå†…è”åˆ°å“åº”)
 */
export async function generateAgentResponseWithTools(
  prompt: string,
  context: AgentContext = {},
  config: AgentConfig = DEFAULT_CONFIG
): Promise<AgentResponse> {
  // æ£€æµ‹æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
  const promptLower = prompt.toLowerCase();
  let toolContext = '';

  if (promptLower.includes('price') && (promptLower.includes('sol') || promptLower.includes('btc') || promptLower.includes('eth') || promptLower.includes('kmt'))) {
    const symbols = ['SOL', 'BTC', 'ETH', 'KMT'].filter(s => promptLower.includes(s.toLowerCase()));
    const prices = await Promise.all(symbols.map(s => getTokenPrice(s)));
    toolContext = `\n\nCurrent prices: ${prices.map(p => `${p.symbol}: $${p.price}`).join(', ')}`;
  }

  // æ·»åŠ å·¥å…·ä¸Šä¸‹æ–‡åˆ° prompt
  const enhancedPrompt = toolContext ? `${prompt}${toolContext}` : prompt;
  
  return generateAgentResponse(enhancedPrompt, context, config);
}

/**
 * é™çº§å“åº” (å½“æ²¡æœ‰ AI provider æ—¶)
 */
function generateFallbackResponse(
  prompt: string,
  context: AgentContext
): AgentResponse {
  const kolHandle = context.kolHandle;
  const persona = kolHandle ? getKOLPersona(kolHandle) : null;
  const kolName = persona?.name || 'AI Assistant';

  const promptLower = prompt.toLowerCase();
  let text: string;

  if (promptLower.includes('gm') || promptLower.includes('hello') || promptLower.includes('hi')) {
    text = `GM! ğŸ‘‹ I'm ${kolName}'s digital twin. AI service is currently in demo mode. What's your alpha today?`;
  } else if (promptLower.includes('price') || promptLower.includes('token')) {
    text = `ğŸš€ ${kolName} here! Token prices are looking bullish. For real-time data, connect your API keys. WAGMI!`;
  } else {
    text = `ğŸš€ ${kolName} here! I'm in demo mode right now. You asked: "${prompt.slice(0, 50)}..." Configure OPENAI_API_KEY for full functionality!`;
  }

  return { text, finishReason: 'demo' };
}

// ============ å·¥å…·å‡½æ•° ============

/**
 * æ£€æŸ¥ AI æœåŠ¡æ˜¯å¦å¯ç”¨
 */
export function isAIServiceAvailable(): boolean {
  return !!process.env.OPENAI_API_KEY;
}

/**
 * è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
 */
export function getAvailableModels(): string[] {
  if (process.env.OPENAI_API_KEY) {
    return ['gpt-4o-mini', 'gpt-4o', 'gpt-4-turbo', 'gpt-3.5-turbo'];
  }
  return ['demo'];
}
